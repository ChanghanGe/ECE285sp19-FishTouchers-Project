{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from PIL import Image\n",
    "import torchvision as tv\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual block\n",
    "class res_block(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super(res_block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(C, C, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(C, C, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(C)\n",
    "        self.bn2 = nn.BatchNorm2d(C)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.conv1(x)\n",
    "        h = self.bn1(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(h)\n",
    "        h = self.bn2(h)\n",
    "        h = h + x\n",
    "        y = F.relu(h)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "# Non-Residual block\n",
    "class non_res_block(nn.Module):\n",
    "    def __init__(self, C_in, C_out, k=3, mode='normal'):\n",
    "        super(non_res_block, self).__init__()\n",
    "        self.conv = nn.Conv2d(C_in, C_out, k, padding=np.int((k-1)/2))\n",
    "        self.bn = nn.BatchNorm2d(C_out)\n",
    "        self.mode = mode\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)\n",
    "        h = self.bn(h)\n",
    "        if self.mode == 'normal':\n",
    "            y = F.relu(h)\n",
    "        else:\n",
    "            y = torch.tanh(h)\n",
    "                \n",
    "        return y\n",
    "    \n",
    "# Transformation network\n",
    "class TransNet(nn.Module):\n",
    "    def __init__(self, D=5):\n",
    "        super(TransNet, self).__init__()\n",
    "        self.D = D\n",
    "        self.up1 = non_res_block(3, 32, k=9)\n",
    "        self.up2 = non_res_block(32, 64)\n",
    "        self.up3 = non_res_block(64, 128)\n",
    "        self.res = nn.ModuleList()\n",
    "        for ii in range(self.D):\n",
    "            self.res.append(non_res_block(128, 128))\n",
    "        self.dn1 = non_res_block(128, 64)\n",
    "        self.dn2 = non_res_block(64, 32)\n",
    "        self.dn3 = non_res_block(32, 3, k=9, mode='last')\n",
    "        \n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "    def forward(self, x): \n",
    "        h = self.up1(x)\n",
    "        h = self.up2(h)\n",
    "        h = self.up3(h)\n",
    "        \n",
    "        for ii in range(self.D):\n",
    "            h = self.res[ii](h)\n",
    "            \n",
    "        h = self.dn1(h)\n",
    "        h = self.dn2(h)\n",
    "        y = self.dn3(h)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "def image_loader(img_path):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    transform = tv.transforms.Compose([\n",
    "        tv.transforms.Resize([512, 512]),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
    "        ])\n",
    "    x = transform(img).view([1, 3, 512, 512])\n",
    "    return x\n",
    "\n",
    "def imshow(image, ax=plt):\n",
    "    image = image.to('cpu').numpy()\n",
    "    image = np.moveaxis(image, [0, 1, 2], [2, 0, 1])\n",
    "    image = (image + 1) / 2\n",
    "    image[image < 0] = 0\n",
    "    image[image > 1] = 1\n",
    "    h = ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model loaded\n"
     ]
    }
   ],
   "source": [
    "model_dir = os.getcwd() + '/Models/'\n",
    "style = 'scream'\n",
    "ratio = '4e3'\n",
    "p_fn = model_dir+style+'.txt'\n",
    "c_fn = model_dir+style+'.pth.tar'\n",
    "\n",
    "if os.path.isfile(c_fn):\n",
    "    checkpoint = torch.load(c_fn)\n",
    "    transnet = TransNet().to(device)\n",
    "    transnet.load_state_dict(checkpoint)\n",
    "    del checkpoint\n",
    "    print('Trained model loaded')\n",
    "else:\n",
    "    print('Model not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read a new frame:  True\n",
      "1\n",
      "Read a new frame:  True\n",
      "2\n",
      "Read a new frame:  True\n",
      "3\n",
      "Read a new frame:  True\n",
      "4\n",
      "Read a new frame:  True\n",
      "5\n",
      "Read a new frame:  True\n",
      "6\n",
      "Read a new frame:  True\n",
      "7\n",
      "Read a new frame:  True\n",
      "8\n",
      "Read a new frame:  True\n",
      "9\n",
      "Read a new frame:  True\n",
      "10\n",
      "Read a new frame:  True\n",
      "11\n",
      "Read a new frame:  True\n",
      "12\n",
      "Read a new frame:  True\n",
      "13\n",
      "Read a new frame:  True\n",
      "14\n",
      "Read a new frame:  True\n",
      "15\n",
      "Read a new frame:  True\n",
      "16\n",
      "Read a new frame:  True\n",
      "17\n",
      "Read a new frame:  True\n",
      "18\n",
      "Read a new frame:  True\n",
      "19\n",
      "Read a new frame:  True\n",
      "20\n",
      "Read a new frame:  True\n",
      "21\n",
      "Read a new frame:  True\n",
      "22\n",
      "Read a new frame:  True\n",
      "23\n",
      "Read a new frame:  True\n",
      "24\n",
      "Read a new frame:  True\n",
      "25\n",
      "Read a new frame:  True\n",
      "26\n",
      "Read a new frame:  True\n",
      "27\n",
      "Read a new frame:  True\n",
      "28\n",
      "Read a new frame:  True\n",
      "29\n",
      "Read a new frame:  True\n",
      "30\n",
      "Read a new frame:  True\n",
      "31\n",
      "Read a new frame:  True\n",
      "32\n",
      "Read a new frame:  True\n",
      "33\n",
      "Read a new frame:  True\n",
      "34\n",
      "Read a new frame:  True\n",
      "35\n",
      "Read a new frame:  True\n",
      "36\n",
      "Read a new frame:  True\n",
      "37\n",
      "Read a new frame:  True\n",
      "38\n",
      "Read a new frame:  True\n",
      "39\n",
      "Read a new frame:  True\n",
      "40\n",
      "Read a new frame:  True\n",
      "41\n",
      "Read a new frame:  True\n",
      "42\n",
      "Read a new frame:  True\n",
      "43\n",
      "Read a new frame:  True\n",
      "44\n",
      "Read a new frame:  True\n",
      "45\n",
      "Read a new frame:  True\n",
      "46\n",
      "Read a new frame:  True\n",
      "47\n",
      "Read a new frame:  True\n",
      "48\n",
      "Read a new frame:  True\n",
      "49\n",
      "Read a new frame:  True\n",
      "50\n",
      "Read a new frame:  True\n",
      "51\n",
      "Read a new frame:  True\n",
      "52\n",
      "Read a new frame:  True\n",
      "53\n",
      "Read a new frame:  True\n",
      "54\n",
      "Read a new frame:  True\n",
      "55\n",
      "Read a new frame:  True\n",
      "56\n",
      "Read a new frame:  True\n",
      "57\n",
      "Read a new frame:  True\n",
      "58\n",
      "Read a new frame:  True\n",
      "59\n",
      "Read a new frame:  True\n",
      "60\n",
      "Read a new frame:  True\n",
      "61\n",
      "Read a new frame:  True\n",
      "62\n",
      "Read a new frame:  True\n",
      "63\n",
      "Read a new frame:  False\n",
      "64\n",
      "7.279059171676636\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "start=time.time()\n",
    "vidcap = cv2.VideoCapture(os.getcwd()+'/video/funny.mp4')\n",
    "if not os.path.exists('temp_frame'):\n",
    "    os.makedirs('temp_frame')\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "while success:    \n",
    "\n",
    "    image=Image.fromarray(image)\n",
    "    transform = tv.transforms.Compose([\n",
    "        tv.transforms.Resize([512, 512]),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize([0,0,0], [1,1,1])\n",
    "        ])\n",
    "    image = transform(image).view([1, 3, 512, 512])\n",
    "    \n",
    "    content_img = image.view([1, 3, 512, 512]).to(device)\n",
    "    content_img[:,0,:,:],content_img[:,2,:,:]=content_img[:,2,:,:],content_img[:,0,:,:]\n",
    "    content_img[:,2,:,:],content_img[:,1,:,:]=content_img[:,1,:,:],content_img[:,2,:,:]\n",
    "\n",
    "#     content_img = image_loader('frog/frame'+str(count)+'.jpg').view([1, 3, 512, 512]).to(device)\n",
    "    transfered_img = transnet(content_img)\n",
    "\n",
    "    \n",
    "    tv.utils.save_image(transfered_img.view([3, 512, 512]),'temp_frame/transfer'+str(count)+'.jpg',normalize=True)\n",
    "    \n",
    "    success,image = vidcap.read()\n",
    "    print('Read a new frame: ', success)\n",
    "    count += 1\n",
    "    print(count)\n",
    "end=time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import natsort \n",
    "\n",
    "name = sorted(glob.glob('temp_frame/transfer*.jpg'))\n",
    "# print(natsort.natsorted(name,reverse=False))\n",
    "name_sorted=natsort.natsorted(name,reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "img_array = []\n",
    "for filename in name_sorted:\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "    \n",
    "# print(img_array[0].shape)\n",
    "\n",
    "\n",
    "out = cv2.VideoWriter('project.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 30, size)\n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoooo = sorted(glob.glob('*.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project.mp4']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videoooo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
